{"status":"ok","feed":{"url":"https://medium.com/feed/@kajolkabiraj6","title":"Stories by kjo-codes on Medium","link":"https://medium.com/@kajolkabiraj6?source=rss-29ce35408d19------2","author":"","description":"Stories by kjo-codes on Medium","image":"https://cdn-images-1.medium.com/fit/c/150/150/0*w3K0H3AJktHtNUrn"},"items":[{"title":"Kubernetes: The Cloud-Native Powerhouse and Why It\u2019s a Scarce Skill","pubDate":"2024-08-13 18:37:11","link":"https://medium.com/@kajolkabiraj6/kubernetes-the-cloud-native-powerhouse-and-why-its-a-scarce-skill-607c81375bfb?source=rss-29ce35408d19------2","guid":"https://medium.com/p/607c81375bfb","author":"kjo-codes","thumbnail":"","description":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*S0KphvgHj8cpwNB4LQtuxQ.png\"></figure><p>In the world of cloud computing and containerization, Kubernetes has emerged as an essential tool for managing and orchestrating containers at scale. Originally developed by Google, Kubernetes (often abbreviated as K8s) has become the de facto standard for container orchestration, powering some of the largest and most complex applications on the planet. However, despite its widespread adoption, there\u2019s a significant shortage of professionals skilled in Kubernetes, making it one of the most coveted skills in the tech industry today. So, why is Kubernetes so critical, and why are there so few people who truly understand it?</p>\n<h3>Why Kubernetes is\u00a0Critical</h3>\n<p>Kubernetes is often referred to as the \u201coperating system of the cloud.\u201d It abstracts the underlying infrastructure, whether it\u2019s cloud-based, on-premises, or hybrid, allowing developers to focus on their applications rather than the complexities of the environment they run in. This abstraction is similar to how traditional operating systems allow applications to run on different types of hardware without modification.</p>\n<p>Kubernetes excels in automating the deployment, scaling, and operation of application containers across clusters of hosts. It also provides features like self-healing, where it automatically restarts failed containers and reschedules them on healthy nodes, and horizontal scaling, which adjusts the number of running containers based on\u00a0demand\u200b.</p>\n<h3>The Scarcity of Kubernetes Skills</h3>\n<p>Despite its importance, Kubernetes remains a complex and challenging technology to master. A recent survey by VMware highlighted that one of the most significant bottlenecks for organizations adopting Kubernetes is the lack of internal experience and expertise. This skills gap is not just about knowing how to use Kubernetes, but also about integrating it with existing systems, ensuring security, and maintaining it over\u00a0time\u200b.</p>\n<p>Kubernetes\u2019 steep learning curve is another factor contributing to the scarcity of skilled professionals. The platform requires a deep understanding of not only containerization but also networking, security, and infrastructure as code. As Kubernetes evolves, the complexity increases, making continuous learning essential. Many organizations struggle to find professionals who have both the experience and the up-to-date knowledge required to effectively manage Kubernetes environments\u200b\u00a0.</p>\n<h3>Real-World Data and the Growing\u00a0Demand</h3>\n<p>The demand for Kubernetes expertise is skyrocketing. According to the Cloud Native Computing Foundation (CNCF), over 60% of enterprises are using Kubernetes, with adoption rising to 96% in some sectors. Yet, there are still only around 5.6 million developers worldwide who are proficient in Kubernetes. This gap between demand and supply makes Kubernetes professionals some of the most sought-after talent in the tech industry\u200b.</p>\n<p>The global Kubernetes market is expected to grow at a compound annual growth rate (CAGR) of 23.4%, reaching unprecedented levels by 2031. This rapid growth is fueled by the increasing adoption of cloud-native technologies across various industries, including IT, telecommunications, healthcare, and finance. As businesses continue to shift towards microservices and containerized applications, the need for skilled Kubernetes engineers will only increase\u200b\u00a0.</p>\n<h3>Why Are So Few People Skilled in Kubernetes?</h3>\n<p>One of the primary reasons for the scarcity of Kubernetes talent is the complexity of the platform itself. Kubernetes requires a different way of thinking about infrastructure, one that is centered around microservices, container orchestration, and automation. Traditional IT professionals often need significant retraining to understand and manage Kubernetes environments effectively.</p>\n<p>Moreover, many organizations have been slow to invest in the necessary training and upskilling programs. A survey by Red Hat revealed that skillset or talent gaps are among the top barriers to successful digital transformation, particularly when it comes to adopting new technologies like Kubernetes. Without dedicated efforts to bridge these gaps, the shortage of Kubernetes skills is likely to persist\u200b.</p>\n<h3>Conclusion: The Future of Kubernetes and Learning Resources</h3>\n<p>Kubernetes is not just a buzzword; it\u2019s a fundamental technology that\u2019s reshaping the way we build, deploy, and scale applications. As its adoption continues to grow, so does the need for skilled professionals who can navigate its complexities. For those willing to invest the time and effort, mastering Kubernetes can open doors to some of the most exciting and well-paying opportunities in tech\u00a0today.</p>\n<p>For those looking to dive into Kubernetes, there are numerous resources available. Platforms offer comprehensive courses on Kubernetes, while community-driven sites like the Cloud Native Computing Foundation provide a wealth of knowledge and certification paths. Additionally, learning platforms like Udemy and Coursera offer beginner to advanced courses that can help you get\u00a0started.</p>\n<p>Understanding Kubernetes may be challenging, but with the right resources and commitment, it\u2019s a skill that can significantly enhance your career in today\u2019s cloud-centric world.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=607c81375bfb\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*S0KphvgHj8cpwNB4LQtuxQ.png\"></figure><p>In the world of cloud computing and containerization, Kubernetes has emerged as an essential tool for managing and orchestrating containers at scale. Originally developed by Google, Kubernetes (often abbreviated as K8s) has become the de facto standard for container orchestration, powering some of the largest and most complex applications on the planet. However, despite its widespread adoption, there\u2019s a significant shortage of professionals skilled in Kubernetes, making it one of the most coveted skills in the tech industry today. So, why is Kubernetes so critical, and why are there so few people who truly understand it?</p>\n<h3>Why Kubernetes is\u00a0Critical</h3>\n<p>Kubernetes is often referred to as the \u201coperating system of the cloud.\u201d It abstracts the underlying infrastructure, whether it\u2019s cloud-based, on-premises, or hybrid, allowing developers to focus on their applications rather than the complexities of the environment they run in. This abstraction is similar to how traditional operating systems allow applications to run on different types of hardware without modification.</p>\n<p>Kubernetes excels in automating the deployment, scaling, and operation of application containers across clusters of hosts. It also provides features like self-healing, where it automatically restarts failed containers and reschedules them on healthy nodes, and horizontal scaling, which adjusts the number of running containers based on\u00a0demand\u200b.</p>\n<h3>The Scarcity of Kubernetes Skills</h3>\n<p>Despite its importance, Kubernetes remains a complex and challenging technology to master. A recent survey by VMware highlighted that one of the most significant bottlenecks for organizations adopting Kubernetes is the lack of internal experience and expertise. This skills gap is not just about knowing how to use Kubernetes, but also about integrating it with existing systems, ensuring security, and maintaining it over\u00a0time\u200b.</p>\n<p>Kubernetes\u2019 steep learning curve is another factor contributing to the scarcity of skilled professionals. The platform requires a deep understanding of not only containerization but also networking, security, and infrastructure as code. As Kubernetes evolves, the complexity increases, making continuous learning essential. Many organizations struggle to find professionals who have both the experience and the up-to-date knowledge required to effectively manage Kubernetes environments\u200b\u00a0.</p>\n<h3>Real-World Data and the Growing\u00a0Demand</h3>\n<p>The demand for Kubernetes expertise is skyrocketing. According to the Cloud Native Computing Foundation (CNCF), over 60% of enterprises are using Kubernetes, with adoption rising to 96% in some sectors. Yet, there are still only around 5.6 million developers worldwide who are proficient in Kubernetes. This gap between demand and supply makes Kubernetes professionals some of the most sought-after talent in the tech industry\u200b.</p>\n<p>The global Kubernetes market is expected to grow at a compound annual growth rate (CAGR) of 23.4%, reaching unprecedented levels by 2031. This rapid growth is fueled by the increasing adoption of cloud-native technologies across various industries, including IT, telecommunications, healthcare, and finance. As businesses continue to shift towards microservices and containerized applications, the need for skilled Kubernetes engineers will only increase\u200b\u00a0.</p>\n<h3>Why Are So Few People Skilled in Kubernetes?</h3>\n<p>One of the primary reasons for the scarcity of Kubernetes talent is the complexity of the platform itself. Kubernetes requires a different way of thinking about infrastructure, one that is centered around microservices, container orchestration, and automation. Traditional IT professionals often need significant retraining to understand and manage Kubernetes environments effectively.</p>\n<p>Moreover, many organizations have been slow to invest in the necessary training and upskilling programs. A survey by Red Hat revealed that skillset or talent gaps are among the top barriers to successful digital transformation, particularly when it comes to adopting new technologies like Kubernetes. Without dedicated efforts to bridge these gaps, the shortage of Kubernetes skills is likely to persist\u200b.</p>\n<h3>Conclusion: The Future of Kubernetes and Learning Resources</h3>\n<p>Kubernetes is not just a buzzword; it\u2019s a fundamental technology that\u2019s reshaping the way we build, deploy, and scale applications. As its adoption continues to grow, so does the need for skilled professionals who can navigate its complexities. For those willing to invest the time and effort, mastering Kubernetes can open doors to some of the most exciting and well-paying opportunities in tech\u00a0today.</p>\n<p>For those looking to dive into Kubernetes, there are numerous resources available. Platforms offer comprehensive courses on Kubernetes, while community-driven sites like the Cloud Native Computing Foundation provide a wealth of knowledge and certification paths. Additionally, learning platforms like Udemy and Coursera offer beginner to advanced courses that can help you get\u00a0started.</p>\n<p>Understanding Kubernetes may be challenging, but with the right resources and commitment, it\u2019s a skill that can significantly enhance your career in today\u2019s cloud-centric world.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=607c81375bfb\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":[]},{"title":"The Day the Blue Screen Returned: How CrowdStrike Glitched the Matrix","pubDate":"2024-08-13 18:31:36","link":"https://medium.com/@kajolkabiraj6/the-day-the-blue-screen-returned-how-crowdstrike-glitched-the-matrix-d52d9b5714d7?source=rss-29ce35408d19------2","guid":"https://medium.com/p/d52d9b5714d7","author":"kjo-codes","thumbnail":"","description":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Hd5Zcypih7-QVJGuwGoGSw.png\"></figure><h3>The Day the Blue Screen\u00a0Returned</h3>\n<p>It was a day like any other in the tech world\u200a\u2014\u200auntil suddenly, it wasn\u2019t. On July 19, 2024, a routine software update turned into a global nightmare. Businesses across the world watched in horror as their computer screens flashed a menacing blue, followed by the dreaded error message: \u201cYour PC ran into a problem and needs to restart.\u201d The Blue Screen of Death (BSOD), a relic from the early days of Windows, had returned with a vengeance.</p>\n<p>This wasn\u2019t just a minor glitch. It was a full-scale tech crisis, and the culprit was none other than CrowdStrike, a company trusted by many to keep their systems safe from cyber threats. But this time, the threat came from\u00a0within.</p>\n<h3>The Glitch Heard Around the\u00a0World</h3>\n<p>The chaos began when CrowdStrike pushed out an update to its Falcon sensor, a tool widely used for endpoint protection. This sensor is supposed to be the digital guardian, blocking attacks and keeping systems secure. But on that fateful day, something went terribly wrong. Instead of protecting the systems, the update caused them to crash, triggering the BSOD and rendering them unusable.</p>\n<p>Imagine the scene: Office floors were suddenly silent, the hum of productivity replaced by the exasperated sighs of employees staring at lifeless screens. In IT departments around the globe, alarms went off, and emergency tickets piled up. Critical infrastructure in industries like finance and healthcare came to a standstill, all because of a single, faulty software\u00a0update.</p>\n<h3>The Technical Breakdown</h3>\n<p>So what exactly went wrong? The issue was traced back to a specific file in the Falcon sensor update\u200a\u2014\u200aC-00000291.sys. This file, essential for the sensor\u2019s operation, had a critical flaw. During the system startup, this file attempted to initialize but encountered an error that caused a conflict with the Windows kernel. This conflict was severe enough to trigger a \"bugcheck\" error, leading to the infamous Blue Screen of\u00a0Death.</p>\n<p>Here\u2019s a simplified look at the problematic file\u00a0path:</p>\n<p>C:\\Windows\\System32\\drivers\\CrowdStrike\\C-00000291.sys</p>\n<p>This file caused a catastrophic error, resulting in systems entering a \u201cdeath loop\u201d where they continuously tried and failed to reboot. For many users, this meant their computers were effectively bricked until a fix could be\u00a0applied.</p>\n<h3>The Fallout: A Global Disruption</h3>\n<p>The impact was immediate and widespread. Businesses were brought to a halt, their operations disrupted as IT teams scrambled to figure out what had gone wrong. For many, the first sign of trouble was a sudden crash, followed by the appearance of the BSOD\u200a\u2014\u200aa sight that many thought was a thing of the\u00a0past.</p>\n<p>The problem wasn\u2019t isolated; it affected thousands of systems globally. The situation was so dire that even major corporations had to halt operations to address the issue. IT teams were in a race against time, working to implement fixes as quickly as possible to minimize downtime.</p>\n<h3>A Worldwide Panic: The IT Community Reacts</h3>\n<p>As the issue spread, the IT community went into overdrive. Forums and social media were flooded with reports of the BSOD, with some describing their systems as being stuck in a \u201cdeath loop,\u201d unable to reboot. It was clear that this was more than just a glitch\u200a\u2014\u200ait was a global\u00a0crisis.</p>\n<p>CrowdStrike quickly acknowledged the problem, but the damage had already been done. IT teams had to spring into action, using every tool at their disposal to fix the issue. The most immediate solution involved booting systems into Safe Mode and manually deleting the faulty file from the system\u2019s\u00a0drivers.</p>\n<h3>Steps to\u00a0Recovery</h3>\n<p>To mitigate the issue, CrowdStrike provided specific steps to recover affected systems. Users were advised to boot their systems into Safe Mode, a diagnostic mode in Windows that loads only the essential drivers. Once in Safe Mode, the problematic C-00000291.sys file needed to be manually deleted from the system using Command\u00a0Prompt:</p>\n<p>del C:\\Windows\\System32\\drivers\\CrowdStrike\\C-00000291*.sys</p>\n<p>Additionally, users could disable the CSAgent service via the Windows Registry to prevent the sensor from loading during startup, which provided an additional layer of security against the BSOD. For those who had restore points available, rolling back the system to a point before the update provided a more straightforward solution.</p>\n<p>CrowdStrike also released an official recovery tool to assist IT administrators in rolling out the fix more efficiently across affected\u00a0systems.</p>\n<h3>Beyond the Glitch: A Sobering\u00a0Lesson</h3>\n<p>This incident wasn\u2019t just a technical failure; it was a stark reminder of the vulnerabilities inherent in our increasingly digital world. When a trusted cybersecurity tool becomes the source of the problem, the ripple effects can be devastating. The Blue Screen of Death, once thought to be a relic of the past, served as a powerful symbol of just how fragile our systems can\u00a0be.</p>\n<p>As businesses recover and CrowdStrike works to ensure this doesn\u2019t happen again, the tech world is left with important questions. How can such critical updates be better tested? What safeguards need to be in place to prevent similar incidents in the\u00a0future?</p>\n<p>For now, one thing is clear: July 19, 2024, will be remembered as the day the Blue Screen of Death made its unexpected and unwelcome return, reminding us all that even the most advanced systems can falter in the blink of an\u00a0eye.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d52d9b5714d7\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Hd5Zcypih7-QVJGuwGoGSw.png\"></figure><h3>The Day the Blue Screen\u00a0Returned</h3>\n<p>It was a day like any other in the tech world\u200a\u2014\u200auntil suddenly, it wasn\u2019t. On July 19, 2024, a routine software update turned into a global nightmare. Businesses across the world watched in horror as their computer screens flashed a menacing blue, followed by the dreaded error message: \u201cYour PC ran into a problem and needs to restart.\u201d The Blue Screen of Death (BSOD), a relic from the early days of Windows, had returned with a vengeance.</p>\n<p>This wasn\u2019t just a minor glitch. It was a full-scale tech crisis, and the culprit was none other than CrowdStrike, a company trusted by many to keep their systems safe from cyber threats. But this time, the threat came from\u00a0within.</p>\n<h3>The Glitch Heard Around the\u00a0World</h3>\n<p>The chaos began when CrowdStrike pushed out an update to its Falcon sensor, a tool widely used for endpoint protection. This sensor is supposed to be the digital guardian, blocking attacks and keeping systems secure. But on that fateful day, something went terribly wrong. Instead of protecting the systems, the update caused them to crash, triggering the BSOD and rendering them unusable.</p>\n<p>Imagine the scene: Office floors were suddenly silent, the hum of productivity replaced by the exasperated sighs of employees staring at lifeless screens. In IT departments around the globe, alarms went off, and emergency tickets piled up. Critical infrastructure in industries like finance and healthcare came to a standstill, all because of a single, faulty software\u00a0update.</p>\n<h3>The Technical Breakdown</h3>\n<p>So what exactly went wrong? The issue was traced back to a specific file in the Falcon sensor update\u200a\u2014\u200aC-00000291.sys. This file, essential for the sensor\u2019s operation, had a critical flaw. During the system startup, this file attempted to initialize but encountered an error that caused a conflict with the Windows kernel. This conflict was severe enough to trigger a \"bugcheck\" error, leading to the infamous Blue Screen of\u00a0Death.</p>\n<p>Here\u2019s a simplified look at the problematic file\u00a0path:</p>\n<p>C:\\Windows\\System32\\drivers\\CrowdStrike\\C-00000291.sys</p>\n<p>This file caused a catastrophic error, resulting in systems entering a \u201cdeath loop\u201d where they continuously tried and failed to reboot. For many users, this meant their computers were effectively bricked until a fix could be\u00a0applied.</p>\n<h3>The Fallout: A Global Disruption</h3>\n<p>The impact was immediate and widespread. Businesses were brought to a halt, their operations disrupted as IT teams scrambled to figure out what had gone wrong. For many, the first sign of trouble was a sudden crash, followed by the appearance of the BSOD\u200a\u2014\u200aa sight that many thought was a thing of the\u00a0past.</p>\n<p>The problem wasn\u2019t isolated; it affected thousands of systems globally. The situation was so dire that even major corporations had to halt operations to address the issue. IT teams were in a race against time, working to implement fixes as quickly as possible to minimize downtime.</p>\n<h3>A Worldwide Panic: The IT Community Reacts</h3>\n<p>As the issue spread, the IT community went into overdrive. Forums and social media were flooded with reports of the BSOD, with some describing their systems as being stuck in a \u201cdeath loop,\u201d unable to reboot. It was clear that this was more than just a glitch\u200a\u2014\u200ait was a global\u00a0crisis.</p>\n<p>CrowdStrike quickly acknowledged the problem, but the damage had already been done. IT teams had to spring into action, using every tool at their disposal to fix the issue. The most immediate solution involved booting systems into Safe Mode and manually deleting the faulty file from the system\u2019s\u00a0drivers.</p>\n<h3>Steps to\u00a0Recovery</h3>\n<p>To mitigate the issue, CrowdStrike provided specific steps to recover affected systems. Users were advised to boot their systems into Safe Mode, a diagnostic mode in Windows that loads only the essential drivers. Once in Safe Mode, the problematic C-00000291.sys file needed to be manually deleted from the system using Command\u00a0Prompt:</p>\n<p>del C:\\Windows\\System32\\drivers\\CrowdStrike\\C-00000291*.sys</p>\n<p>Additionally, users could disable the CSAgent service via the Windows Registry to prevent the sensor from loading during startup, which provided an additional layer of security against the BSOD. For those who had restore points available, rolling back the system to a point before the update provided a more straightforward solution.</p>\n<p>CrowdStrike also released an official recovery tool to assist IT administrators in rolling out the fix more efficiently across affected\u00a0systems.</p>\n<h3>Beyond the Glitch: A Sobering\u00a0Lesson</h3>\n<p>This incident wasn\u2019t just a technical failure; it was a stark reminder of the vulnerabilities inherent in our increasingly digital world. When a trusted cybersecurity tool becomes the source of the problem, the ripple effects can be devastating. The Blue Screen of Death, once thought to be a relic of the past, served as a powerful symbol of just how fragile our systems can\u00a0be.</p>\n<p>As businesses recover and CrowdStrike works to ensure this doesn\u2019t happen again, the tech world is left with important questions. How can such critical updates be better tested? What safeguards need to be in place to prevent similar incidents in the\u00a0future?</p>\n<p>For now, one thing is clear: July 19, 2024, will be remembered as the day the Blue Screen of Death made its unexpected and unwelcome return, reminding us all that even the most advanced systems can falter in the blink of an\u00a0eye.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d52d9b5714d7\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":[]},{"title":"The Rise of Generative AI: Transforming Creativity and Productivity","pubDate":"2024-08-13 18:16:27","link":"https://medium.com/@kajolkabiraj6/the-rise-of-generative-ai-transforming-creativity-and-productivity-149a90f926bb?source=rss-29ce35408d19------2","guid":"https://medium.com/p/149a90f926bb","author":"kjo-codes","thumbnail":"","description":"\n<p>In today\u2019s fast-paced technological landscape, a new player is emerging as a transformative force\u200a\u2014\u200aGenerative AI, or GenAI. This innovative technology is not just reshaping the creative industries but is also making waves across various sectors. But what is Generative AI, and how is it changing the way we create and\u00a0work?</p>\n<p><strong>Understanding Generative AI: The Creative\u00a0Engine</strong></p>\n<p>Imagine a machine that can paint like Picasso, write like Shakespeare, or compose music like Mozart. Generative AI is that machine\u200a\u2014\u200aa powerful engine of creativity. Unlike traditional AI, which is primarily analytical, Generative AI creates new content, learning from vast amounts of data and then generating original\u00a0outputs.</p>\n<p>For example, consider a digital artist who wants to create a series of futuristic cityscapes. With Generative AI, the artist can input basic concepts or themes, and the AI will generate a variety of cityscapes, each unique and complex. This doesn\u2019t just save time; it opens up new creative possibilities.</p>\n<p><strong>Transforming Industries: The Reach of Generative AI</strong></p>\n<p>Generative AI is more than just a creative tool\u200a\u2014\u200ait\u2019s a disruptive force across multiple industries. Here\u2019s\u00a0how:</p>\n<p>1. Entertainment and Media:<br>\u200a\u2014\u200aContent Creation: GenAI is already writing movie scripts, generating storyboards, and even designing characters. Imagine an AI co-writer that can instantly generate alternative endings to a story, giving screenwriters endless possibilities to explore.<br>\u200a\u2014\u200aGaming: In video game development, GenAI can create entire worlds, designing levels and characters that evolve with the player\u2019s actions, providing a more immersive experience.</p>\n<p>2. Marketing and Advertising:<br>\u200a\u2014\u200aPersonalized Campaigns: Marketers are using GenAI to craft personalized messages and ads. For example, an AI could generate a hundred different versions of an ad, each tailored to a specific audience segment, increasing engagement and conversion rates.<br>\u200a\u2014\u200aBrand Identity: GenAI can even help in designing logos or creating brand identities from scratch, offering multiple creative options that align with a company\u2019s vision.</p>\n<p>3. Healthcare:<br>\u200a\u2014\u200aDrug Discovery: By analyzing vast datasets, GenAI can identify potential drug candidates much faster than traditional methods. Think of it as having a supercomputer that can sort through millions of molecular combinations in a fraction of the time.<br>\u200a\u2014\u200aSynthetic Data Generation: For research purposes, GenAI can generate synthetic patient data, allowing scientists to conduct experiments without risking patient\u00a0privacy.</p>\n<p>4. Finance:<br>\u200a\u2014\u200aMarket Analysis: Financial analysts can use GenAI to generate reports, predict market trends, and even automate trading strategies. Imagine an AI that can read and analyze thousands of financial reports in seconds, providing insights that would take humans days to uncover.<br>\u200a\u2014\u200aFraud Detection: GenAI can also detect unusual patterns in transactions, flagging potential fraud much faster than traditional systems.</p>\n<p><strong>Challenges and Ethical Considerations: The Double-Edged Sword</strong></p>\n<p>While the potential of Generative AI is immense, it comes with its own set of challenges. For one, the technology can be used to create deepfakes\u200a\u2014\u200arealistic but fake images or videos that can spread misinformation. Additionally, the rise of GenAI raises ethical questions about job displacement, as machines take over tasks traditionally done by\u00a0humans.</p>\n<p>There\u2019s also the issue of intellectual property. If an AI generates a piece of artwork or a piece of music, who owns the rights? The creator of the AI? The AI itself? These are questions that society will need to address as the technology evolves.</p>\n<p><strong>The Future of Generative AI: A World of Possibilities</strong></p>\n<p>Generative AI is not just a trend; it\u2019s a paradigm shift in how we think about creativity and work. In the future, we could see GenAI becoming a standard tool in everything from education to space exploration. Imagine a classroom where AI helps students write essays, offering suggestions and guidance tailored to each student\u2019s learning\u00a0style.</p>\n<p>However, with great power comes great responsibility. As we integrate GenAI into our lives, it\u2019s crucial to develop ethical guidelines and best practices to ensure that this technology is used for\u00a0good.</p>\n<p>In conclusion, Generative AI is more than just a tool\u200a\u2014\u200ait\u2019s a partner in creativity and productivity, capable of unlocking new potentials across industries. Whether you\u2019re a creative professional, a business leader, or a tech enthusiast, understanding Generative AI could be your gateway to the\u00a0future.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=149a90f926bb\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>In today\u2019s fast-paced technological landscape, a new player is emerging as a transformative force\u200a\u2014\u200aGenerative AI, or GenAI. This innovative technology is not just reshaping the creative industries but is also making waves across various sectors. But what is Generative AI, and how is it changing the way we create and\u00a0work?</p>\n<p><strong>Understanding Generative AI: The Creative\u00a0Engine</strong></p>\n<p>Imagine a machine that can paint like Picasso, write like Shakespeare, or compose music like Mozart. Generative AI is that machine\u200a\u2014\u200aa powerful engine of creativity. Unlike traditional AI, which is primarily analytical, Generative AI creates new content, learning from vast amounts of data and then generating original\u00a0outputs.</p>\n<p>For example, consider a digital artist who wants to create a series of futuristic cityscapes. With Generative AI, the artist can input basic concepts or themes, and the AI will generate a variety of cityscapes, each unique and complex. This doesn\u2019t just save time; it opens up new creative possibilities.</p>\n<p><strong>Transforming Industries: The Reach of Generative AI</strong></p>\n<p>Generative AI is more than just a creative tool\u200a\u2014\u200ait\u2019s a disruptive force across multiple industries. Here\u2019s\u00a0how:</p>\n<p>1. Entertainment and Media:<br>\u200a\u2014\u200aContent Creation: GenAI is already writing movie scripts, generating storyboards, and even designing characters. Imagine an AI co-writer that can instantly generate alternative endings to a story, giving screenwriters endless possibilities to explore.<br>\u200a\u2014\u200aGaming: In video game development, GenAI can create entire worlds, designing levels and characters that evolve with the player\u2019s actions, providing a more immersive experience.</p>\n<p>2. Marketing and Advertising:<br>\u200a\u2014\u200aPersonalized Campaigns: Marketers are using GenAI to craft personalized messages and ads. For example, an AI could generate a hundred different versions of an ad, each tailored to a specific audience segment, increasing engagement and conversion rates.<br>\u200a\u2014\u200aBrand Identity: GenAI can even help in designing logos or creating brand identities from scratch, offering multiple creative options that align with a company\u2019s vision.</p>\n<p>3. Healthcare:<br>\u200a\u2014\u200aDrug Discovery: By analyzing vast datasets, GenAI can identify potential drug candidates much faster than traditional methods. Think of it as having a supercomputer that can sort through millions of molecular combinations in a fraction of the time.<br>\u200a\u2014\u200aSynthetic Data Generation: For research purposes, GenAI can generate synthetic patient data, allowing scientists to conduct experiments without risking patient\u00a0privacy.</p>\n<p>4. Finance:<br>\u200a\u2014\u200aMarket Analysis: Financial analysts can use GenAI to generate reports, predict market trends, and even automate trading strategies. Imagine an AI that can read and analyze thousands of financial reports in seconds, providing insights that would take humans days to uncover.<br>\u200a\u2014\u200aFraud Detection: GenAI can also detect unusual patterns in transactions, flagging potential fraud much faster than traditional systems.</p>\n<p><strong>Challenges and Ethical Considerations: The Double-Edged Sword</strong></p>\n<p>While the potential of Generative AI is immense, it comes with its own set of challenges. For one, the technology can be used to create deepfakes\u200a\u2014\u200arealistic but fake images or videos that can spread misinformation. Additionally, the rise of GenAI raises ethical questions about job displacement, as machines take over tasks traditionally done by\u00a0humans.</p>\n<p>There\u2019s also the issue of intellectual property. If an AI generates a piece of artwork or a piece of music, who owns the rights? The creator of the AI? The AI itself? These are questions that society will need to address as the technology evolves.</p>\n<p><strong>The Future of Generative AI: A World of Possibilities</strong></p>\n<p>Generative AI is not just a trend; it\u2019s a paradigm shift in how we think about creativity and work. In the future, we could see GenAI becoming a standard tool in everything from education to space exploration. Imagine a classroom where AI helps students write essays, offering suggestions and guidance tailored to each student\u2019s learning\u00a0style.</p>\n<p>However, with great power comes great responsibility. As we integrate GenAI into our lives, it\u2019s crucial to develop ethical guidelines and best practices to ensure that this technology is used for\u00a0good.</p>\n<p>In conclusion, Generative AI is more than just a tool\u200a\u2014\u200ait\u2019s a partner in creativity and productivity, capable of unlocking new potentials across industries. Whether you\u2019re a creative professional, a business leader, or a tech enthusiast, understanding Generative AI could be your gateway to the\u00a0future.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=149a90f926bb\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":[]},{"title":"My Outreachy Adventure: Mapping the Future with HOT\u2019s Osm-Fieldwork Project","pubDate":"2024-03-31 21:26:48","link":"https://medium.com/@kajolkabiraj6/my-outreachy-adventure-mapping-the-future-with-hots-osm-fieldwork-project-d770fa7fa233?source=rss-29ce35408d19------2","guid":"https://medium.com/p/d770fa7fa233","author":"kjo-codes","thumbnail":"","description":"\n<p>Embarking on my Outreachy journey, I found myself drawn to the fascinating world of open source, where collaboration knows no bounds and innovation knows no limits. My first foray into this realm led me to the Humanitarian OpenStreetMap Team (HOT), where I discovered the Osm-Fieldwork project\u200a\u2014\u200aa beacon of innovation in the realm of data collection and\u00a0mapping.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/300/1*0VLmXGwKHV7ML57QnROfWA.png\"></figure><p>Osm-Fieldwork, a project designed to streamline the process of data collection using ODK and transform it into OpenStreetMap format, immediately captured my attention. Its utility programs automate various steps of the data flow, from creating satellite imagery basemaps to extracting data from OpenStreetMap, all of which were previously cumbersome manual\u00a0tasks.</p>\n<p>What truly fascinated me was the project\u2019s versatility\u200a\u2014\u200ait functions seamlessly as the backend of a webpage, yet can also operate standalone and offline, making it accessible even in remote and resource-constrained environments. The simplicity of its command line programs, coupled with its powerful functionality, left me in\u00a0awe.</p>\n<p>Digging deeper, I uncovered the project\u2019s origins in producing emergency response maps in the Western United States, a testament to its practical applications in real-world scenarios. This was further elucidated in a captivating talk titled \u201cOSM For Firefighting\u201d at SOTM-US 2022, where the project\u2019s tech and usage were intricately dissected.</p>\n<p>Now, these innovative tools are an integral part of the backend for the Field Mapping Tasking Manager project at HOT, underscoring their importance in humanitarian efforts worldwide.</p>\n<p>As I delve into my Outreachy adventure, I am excited to contribute to the Osm-Fieldwork project, leveraging my skills and passion to drive positive change in the realm of humanitarian mapping. With each line of code, I am mapping the future\u200a\u2014\u200aone keystroke at a\u00a0time.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d770fa7fa233\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>Embarking on my Outreachy journey, I found myself drawn to the fascinating world of open source, where collaboration knows no bounds and innovation knows no limits. My first foray into this realm led me to the Humanitarian OpenStreetMap Team (HOT), where I discovered the Osm-Fieldwork project\u200a\u2014\u200aa beacon of innovation in the realm of data collection and\u00a0mapping.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/300/1*0VLmXGwKHV7ML57QnROfWA.png\"></figure><p>Osm-Fieldwork, a project designed to streamline the process of data collection using ODK and transform it into OpenStreetMap format, immediately captured my attention. Its utility programs automate various steps of the data flow, from creating satellite imagery basemaps to extracting data from OpenStreetMap, all of which were previously cumbersome manual\u00a0tasks.</p>\n<p>What truly fascinated me was the project\u2019s versatility\u200a\u2014\u200ait functions seamlessly as the backend of a webpage, yet can also operate standalone and offline, making it accessible even in remote and resource-constrained environments. The simplicity of its command line programs, coupled with its powerful functionality, left me in\u00a0awe.</p>\n<p>Digging deeper, I uncovered the project\u2019s origins in producing emergency response maps in the Western United States, a testament to its practical applications in real-world scenarios. This was further elucidated in a captivating talk titled \u201cOSM For Firefighting\u201d at SOTM-US 2022, where the project\u2019s tech and usage were intricately dissected.</p>\n<p>Now, these innovative tools are an integral part of the backend for the Field Mapping Tasking Manager project at HOT, underscoring their importance in humanitarian efforts worldwide.</p>\n<p>As I delve into my Outreachy adventure, I am excited to contribute to the Osm-Fieldwork project, leveraging my skills and passion to drive positive change in the realm of humanitarian mapping. With each line of code, I am mapping the future\u200a\u2014\u200aone keystroke at a\u00a0time.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d770fa7fa233\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":[]},{"title":"How to Build a Serverless Website with reCAPTCHA on AWS","pubDate":"2024-03-31 21:14:51","link":"https://medium.com/@kajolkabiraj6/how-to-build-a-serverless-website-with-recaptcha-on-aws-09d2081339dd?source=rss-29ce35408d19------2","guid":"https://medium.com/p/09d2081339dd","author":"kjo-codes","thumbnail":"","description":"\n<p>This is based on my experience hosting my personal static site on AWS. I don\u2019t want to run the server for just a \u2018Contact Us\u2019 form. Oh, and I also need a Captcha because I don\u2019t want a lot of spam coming in. So I used a serverless site architecture and Google recaptcha for\u00a0that.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/750/1*xOC_IrcitJIZkENBWcrhEw.jpeg\"></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YD_i1XVaTbHKeLrjPcVewQ.png\"></figure><h3>Application Architecture</h3>\n<p>Application architecture used:</p>\n<ol>\n<li>AWS Lambda</li>\n<li>Amazon API\u00a0gateway</li>\n<li>Amazon S3</li>\n<li>Amazon SNS</li>\n<li>Amazon CloudFront 6.Amazon Route\u00a053</li>\n<li>AWS Certificate Manager</li>\n<li>Google reCaptcha</li>\n</ol>\n<h3>Create Buckets on Amazon\u00a0S3</h3>\n<ol>\n<li>Open the console or access Amazon S3\u00a0<a href=\"https://console.aws.amazon.com/s3/\">here</a>\n</li>\n<li>create a bucket with your domain name, for example example.com</li>\n<li>Enough at this point, we will upload the file\u00a0later</li>\n</ol>\n<h3>Create SNS Topics and Subscriptions</h3>\n<ol>\n<li>Open SNS Console or access\u00a0<a href=\"https://console.aws.amazon.com/sns/\">here</a>\n</li>\n<li>Create a name for the\u00a0Topic</li>\n<li>Create a Subscription, select the ARN Topic according to what was made in point\u00a02</li>\n<li>Select email on the protocol type, then create a subscription</li>\n<li>Check the registered email and verify the subscription from\u00a0AWS</li>\n</ol>\n<h3>Build Serverless Back-end on AWS\u00a0Lambda</h3>\n<ol>\n<li>In the <a href=\"https://console.aws.amazon.com/lambda/\">Lambda Console</a>, select the create\u00a0function</li>\n<li>Select Author from\u00a0scratch</li>\n<li>Enter the name of the Function and select Node.js for the\u00a0Runtime</li>\n<li>Then select Create\u00a0function</li>\n</ol>\n<p>At this point we will use lambda with JavaScript. Unfortunately we cannot easily load scripts into the AWS Lambda online editor which has external dependencies such as Axios. So we need to create a Node project with package.json like\u00a0this:</p>\n<pre>{<br>   \"\"name\"\":\"\"contactForm\"\",<br>   \"\"version\"\":\"\"0.0.1\"\",<br>   \"\"private\"\":true,<br>   \"\"scripts\"\":{},<br>   \"\"dependencies\"\":{<br>      \"\"aws-sdk\"\":\"\"^2.560.0\"\",<br>      \"\"axios\"\":\"\"^0.18.0\"\"<br>   }<br>}</pre>\n<p>We will use the environment variable in lambda to make things easier when there are changes to the SNS ARN Topic and the ecret Key of reCaptcha, change index.js as\u00a0follows:</p>\n<pre>'use strict';<br>const AWS = require(\"\"aws-sdk\"\");<br>const axios = require('axios');<br>const completeUrl = \"\"https://www.google.com\"\";<br>// verify recaptcha url<br>const reCapUrl = \"\"https://www.google.com/recaptcha/api/siteverify\"\";<br>const reCaptchaSecret = process.env.RECAPTCHA_SECRET_KEY;<br>// from Amazon SNS<br>const snsTopic = process.env.ARN_SNS_TOPIC;<br>module.exports.handler = async (event, context, callback) =&gt; {<br>    console.log(\"\"Starting ContactForm Processing for website form.\"\");<br>    // console.log(\"\"data event: \"\" + JSON.stringify(event));<br>    // verify the result by POSTing to google backend with secret and frontend recaptcha token as payload<br>    let verifyResult = await axios({<br>        method: 'post',<br>        url: reCapUrl,<br>        params: {<br>            secret: reCaptchaSecret,<br>            response: event.captcha<br>        }<br>    }) // print out the result of that. Its a bit verbose though<br>    // console.log(\"\"verify result: \"\" + JSON.stringify(verifyResult.data));<br>    if (verifyResult.data.success) {<br>        let sns = new AWS.SNS();<br>        // The structure of the email<br>        let emailbody = \"\"Someone left a message for you.\\n\\nName\\t\\t: \"\" + event.name + \"\"\\nEmail\\t\\t: \"\" + event.email + \"\"\\nSubject\\t\\t: \"\" + event.subject + \"\"\\nMessage\\t\\t: \"\" + event.message + \"\"\\n\\nThanks!\"\";<br>        let params = {<br>            Message: emailbody,<br>            Subject: \"\"Contact Form: \"\" + event.subject,<br>            TopicArn: snsTopic<br>        };<br>        // we publish the created message to Amazon SNS now\u7ab6\uff66<br>        sns.publish(params, context.done);<br>        // now we return a HTTP 302 together with a URL to redirect the browser to success URL (we put in google.com for simplicty)<br>        callback(null, {<br>            statusCode: 302,<br>            headers: {<br>                Location: completeUrl,<br>            }<br>        });<br>        console.log(\"\"End of the ContactForm Process With Success\"\");<br>    } else {<br>        console.log(\"\"reCaptcha check failed. Most likely SPAM.\"\");<br>        callback(null, {<br>            statusCode: '500',<br>            body: JSON.stringify({<br>                message: 'Invalid recaptcha'<br>            })<br>        });<br>    }<br>};</pre>\n<p>After creating the project, we need to compress the folder in ZIP format for uploading to\u00a0Lambda.</p>\n<p>While still in the Lambda Console in the previously created Function, upload the ZIP and set the environment variables as\u00a0follows:</p>\n<p>Then select\u00a0Save.</p>\n<h3>Deploy Restful API\u00a0Gateway</h3>\n<ol>\n<li>Open the API Gateway Console or access\u00a0<a href=\"https://console.aws.amazon.com/apigateway/\">here</a>\n</li>\n<li>Select Create API and select\u00a0REST</li>\n<li>Select New API and enter the API\u00a0Name</li>\n<li>Select Create\u00a0API</li>\n<li>On the left navigation, select Resources under your\u00a0API</li>\n<li>From the Actions dropdown menu select Create\u00a0Resource</li>\n<li>Enter a Resource Name such as contact or prod then click Create\u00a0Resource</li>\n<li>On the newly created Resource, from the Action dropdown menu select Create\u00a0Method</li>\n<li>Select Post then checkmark</li>\n<li>Select Lambda Function for integration type</li>\n<li>Select the Region you are using on AWS\u00a0Lambda</li>\n<li>Enter the name of the function that was created before then\u00a0Save</li>\n<li>[Optional CORS] In the newly created resource, from the Action dropdown select Enable CORS then click enable and replacing</li>\n<li>On the Actions dropdown menu select Deploy API, enter the Stage Name then select\u00a0Deploy</li>\n<li>Write down and save the Invoke URL which will be used\u00a0later</li>\n</ol>\n<h3>Set up a serverless website</h3>\n<p>Previously, you could use reCAPTCHA by registering a domain name\u00a0<a href=\"https://www.google.com/recaptcha/admin\">here</a>.</p>\n<h4>HTML</h4>\n<p>We are following the Google reCaptcha documentation, which means we have to enter the code below between the &lt;head&gt; and &lt;/head&gt;\u00a0tags.</p>\n<pre>&lt;script src=\"\"https://www.google.com/recaptcha/api.js\"\"&gt;&lt;/script&gt;</pre>\n<p>and enter the following code at the bottom of the form before the submit button. Don\u2019t forget to enter the siteKey you got after registering the domain on Google reCaptcha.</p>\n<pre>&lt;div class=\"\"g-recaptcha\"\" data-sitekey=\"\"xxxxxxxxxxxxxxxxxxx\"\"&gt;&lt;/div&gt;</pre>\n<h4>JavaScript</h4>\n<p>We can use Ajax to perform asynchronous HTTP (Ajax) requests. Enter the Ajax URL with the Invoke URL we got when building the API\u00a0gateway.</p>\n<h3>Host Static\u00a0Website</h3>\n<ol>\n<li>Back in the S3 Console, select the bucket that was created\u00a0earlier</li>\n<li>Upload your website files into a\u00a0bucket</li>\n<li>When finished, select the Properties tab</li>\n<li>Select Static website\u00a0hosting</li>\n<li>Fill in the index and document\u00a0error</li>\n<li>Make sure Block Public access is not\u00a0checked</li>\n<li>Still on the Permissions tab, select Bucket Policy. Enter the following policy document into the policy bucket editor, replacing [YOUR_BUCKET_NAME] with the bucket name that was\u00a0created.</li>\n</ol>\n<pre>{<br>   \"\"Version\"\":\"\"2012-10-17\"\",<br>   \"\"Statement\"\":[<br>      {<br>         \"\"Effect\"\":\"\"Allow\"\",<br>         \"\"Principal\"\":\"\"*\"\",<br>         \"\"Action\"\":\"\"s3:GetObject\"\",<br>         \"\"Resource\"\":\"\"arn:aws:s3:::[YOUR_BUCKET_NAME]/*\"\"<br>      }<br>   ]<br>}</pre>\n<h3>Configure the Domain on Route\u00a053</h3>\n<ol>\n<li>On Amazon Route 53 we can register a new domain or make Route 53 a DNS service for an existing\u00a0domain</li>\n<li>I already have my own domain, so I made Amazon Route 53 the DNS Service for my\u00a0domain</li>\n<li>On the <a href=\"https://console.aws.amazon.com/route53/home\">Route 53 Console</a>, select Create Hosted\u00a0Zone.</li>\n<li>On the Create Hosted Zone panel, enter the domain\u00a0name</li>\n<li>In the Type, leave the default on the Public Hosted\u00a0Zone</li>\n<li>Select Create.</li>\n</ol>\n<h3>Request SSL Certificate in AWS Certificate Manager</h3>\n<ol>\n<li>Open ACM Console or access\u00a0<a href=\"https://console.aws.amazon.com/apigateway/\">here</a>\n</li>\n<li>select Request a Certificate</li>\n<li>Select Request a public certificate</li>\n<li>Add a domain name with your own domain name, for example example.com or *.example.com</li>\n<li>We need to validate the certificate request, how to select DNS validation or email validation. Here I use DNS validation because it\u2019s faster and\u00a0easier.</li>\n<li>Add a CNAME on Amazon Route 53 or simply click the button below your domain to add it automatically.</li>\n</ol>\n<h3>Create a CloudFront Web Distribution</h3>\n<ol>\n<li>Open the CloudFront console or access\u00a0<a href=\"https://console.aws.amazon.com/cloudfront/home\">here</a>\n</li>\n<li>Create a distribution</li>\n<li>select Origin Domain Name with the bucket name created\u00a0earlier.</li>\n<li>Select Redirect HTTP to\u00a0HTTPS</li>\n<li>Select Yes in the Restrict Bucket Access\u00a0section</li>\n<li>In the Distribution Settings, use the Custom SSL Certificate and select the certificate that was created in\u00a0ACM</li>\n<li>Scroll and find Default Root Object, enter the default file Index.html</li>\n<li>Leave everything else default and create distribution.</li>\n<li>Wait until the status is Deployed, it usually takes a few\u00a0minutes.</li>\n<li>Write down the Domain name from cloudfront</li>\n</ol>\n<h3>Using Custom Domain on Route\u00a053</h3>\n<ol>\n<li>Return to the Route 53\u00a0Console</li>\n<li>Select a domain that has been registered</li>\n<li>Select Create Record\u00a0Set</li>\n<li>We will create 2 record\u00a0sets</li>\n<li>The first is example.com and the second is <a href=\"http://www.example.com/\">www.example.com</a>\n</li>\n<li>Use A record and select the created CloudFront.</li>\n</ol>\n<p>That\u2019s it, we\u2019ve built a serverless static website with reCaptcha protection and a notification for the owner or admin if someone sends a message on the\u00a0form.</p>\n<p>Reference:</p>\n<ol><li>AWS Documentations</li></ol>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=09d2081339dd\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>This is based on my experience hosting my personal static site on AWS. I don\u2019t want to run the server for just a \u2018Contact Us\u2019 form. Oh, and I also need a Captcha because I don\u2019t want a lot of spam coming in. So I used a serverless site architecture and Google recaptcha for\u00a0that.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/750/1*xOC_IrcitJIZkENBWcrhEw.jpeg\"></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YD_i1XVaTbHKeLrjPcVewQ.png\"></figure><h3>Application Architecture</h3>\n<p>Application architecture used:</p>\n<ol>\n<li>AWS Lambda</li>\n<li>Amazon API\u00a0gateway</li>\n<li>Amazon S3</li>\n<li>Amazon SNS</li>\n<li>Amazon CloudFront 6.Amazon Route\u00a053</li>\n<li>AWS Certificate Manager</li>\n<li>Google reCaptcha</li>\n</ol>\n<h3>Create Buckets on Amazon\u00a0S3</h3>\n<ol>\n<li>Open the console or access Amazon S3\u00a0<a href=\"https://console.aws.amazon.com/s3/\">here</a>\n</li>\n<li>create a bucket with your domain name, for example example.com</li>\n<li>Enough at this point, we will upload the file\u00a0later</li>\n</ol>\n<h3>Create SNS Topics and Subscriptions</h3>\n<ol>\n<li>Open SNS Console or access\u00a0<a href=\"https://console.aws.amazon.com/sns/\">here</a>\n</li>\n<li>Create a name for the\u00a0Topic</li>\n<li>Create a Subscription, select the ARN Topic according to what was made in point\u00a02</li>\n<li>Select email on the protocol type, then create a subscription</li>\n<li>Check the registered email and verify the subscription from\u00a0AWS</li>\n</ol>\n<h3>Build Serverless Back-end on AWS\u00a0Lambda</h3>\n<ol>\n<li>In the <a href=\"https://console.aws.amazon.com/lambda/\">Lambda Console</a>, select the create\u00a0function</li>\n<li>Select Author from\u00a0scratch</li>\n<li>Enter the name of the Function and select Node.js for the\u00a0Runtime</li>\n<li>Then select Create\u00a0function</li>\n</ol>\n<p>At this point we will use lambda with JavaScript. Unfortunately we cannot easily load scripts into the AWS Lambda online editor which has external dependencies such as Axios. So we need to create a Node project with package.json like\u00a0this:</p>\n<pre>{<br>   \"\"name\"\":\"\"contactForm\"\",<br>   \"\"version\"\":\"\"0.0.1\"\",<br>   \"\"private\"\":true,<br>   \"\"scripts\"\":{},<br>   \"\"dependencies\"\":{<br>      \"\"aws-sdk\"\":\"\"^2.560.0\"\",<br>      \"\"axios\"\":\"\"^0.18.0\"\"<br>   }<br>}</pre>\n<p>We will use the environment variable in lambda to make things easier when there are changes to the SNS ARN Topic and the ecret Key of reCaptcha, change index.js as\u00a0follows:</p>\n<pre>'use strict';<br>const AWS = require(\"\"aws-sdk\"\");<br>const axios = require('axios');<br>const completeUrl = \"\"https://www.google.com\"\";<br>// verify recaptcha url<br>const reCapUrl = \"\"https://www.google.com/recaptcha/api/siteverify\"\";<br>const reCaptchaSecret = process.env.RECAPTCHA_SECRET_KEY;<br>// from Amazon SNS<br>const snsTopic = process.env.ARN_SNS_TOPIC;<br>module.exports.handler = async (event, context, callback) =&gt; {<br>    console.log(\"\"Starting ContactForm Processing for website form.\"\");<br>    // console.log(\"\"data event: \"\" + JSON.stringify(event));<br>    // verify the result by POSTing to google backend with secret and frontend recaptcha token as payload<br>    let verifyResult = await axios({<br>        method: 'post',<br>        url: reCapUrl,<br>        params: {<br>            secret: reCaptchaSecret,<br>            response: event.captcha<br>        }<br>    }) // print out the result of that. Its a bit verbose though<br>    // console.log(\"\"verify result: \"\" + JSON.stringify(verifyResult.data));<br>    if (verifyResult.data.success) {<br>        let sns = new AWS.SNS();<br>        // The structure of the email<br>        let emailbody = \"\"Someone left a message for you.\\n\\nName\\t\\t: \"\" + event.name + \"\"\\nEmail\\t\\t: \"\" + event.email + \"\"\\nSubject\\t\\t: \"\" + event.subject + \"\"\\nMessage\\t\\t: \"\" + event.message + \"\"\\n\\nThanks!\"\";<br>        let params = {<br>            Message: emailbody,<br>            Subject: \"\"Contact Form: \"\" + event.subject,<br>            TopicArn: snsTopic<br>        };<br>        // we publish the created message to Amazon SNS now\u7ab6\uff66<br>        sns.publish(params, context.done);<br>        // now we return a HTTP 302 together with a URL to redirect the browser to success URL (we put in google.com for simplicty)<br>        callback(null, {<br>            statusCode: 302,<br>            headers: {<br>                Location: completeUrl,<br>            }<br>        });<br>        console.log(\"\"End of the ContactForm Process With Success\"\");<br>    } else {<br>        console.log(\"\"reCaptcha check failed. Most likely SPAM.\"\");<br>        callback(null, {<br>            statusCode: '500',<br>            body: JSON.stringify({<br>                message: 'Invalid recaptcha'<br>            })<br>        });<br>    }<br>};</pre>\n<p>After creating the project, we need to compress the folder in ZIP format for uploading to\u00a0Lambda.</p>\n<p>While still in the Lambda Console in the previously created Function, upload the ZIP and set the environment variables as\u00a0follows:</p>\n<p>Then select\u00a0Save.</p>\n<h3>Deploy Restful API\u00a0Gateway</h3>\n<ol>\n<li>Open the API Gateway Console or access\u00a0<a href=\"https://console.aws.amazon.com/apigateway/\">here</a>\n</li>\n<li>Select Create API and select\u00a0REST</li>\n<li>Select New API and enter the API\u00a0Name</li>\n<li>Select Create\u00a0API</li>\n<li>On the left navigation, select Resources under your\u00a0API</li>\n<li>From the Actions dropdown menu select Create\u00a0Resource</li>\n<li>Enter a Resource Name such as contact or prod then click Create\u00a0Resource</li>\n<li>On the newly created Resource, from the Action dropdown menu select Create\u00a0Method</li>\n<li>Select Post then checkmark</li>\n<li>Select Lambda Function for integration type</li>\n<li>Select the Region you are using on AWS\u00a0Lambda</li>\n<li>Enter the name of the function that was created before then\u00a0Save</li>\n<li>[Optional CORS] In the newly created resource, from the Action dropdown select Enable CORS then click enable and replacing</li>\n<li>On the Actions dropdown menu select Deploy API, enter the Stage Name then select\u00a0Deploy</li>\n<li>Write down and save the Invoke URL which will be used\u00a0later</li>\n</ol>\n<h3>Set up a serverless website</h3>\n<p>Previously, you could use reCAPTCHA by registering a domain name\u00a0<a href=\"https://www.google.com/recaptcha/admin\">here</a>.</p>\n<h4>HTML</h4>\n<p>We are following the Google reCaptcha documentation, which means we have to enter the code below between the &lt;head&gt; and &lt;/head&gt;\u00a0tags.</p>\n<pre>&lt;script src=\"\"https://www.google.com/recaptcha/api.js\"\"&gt;&lt;/script&gt;</pre>\n<p>and enter the following code at the bottom of the form before the submit button. Don\u2019t forget to enter the siteKey you got after registering the domain on Google reCaptcha.</p>\n<pre>&lt;div class=\"\"g-recaptcha\"\" data-sitekey=\"\"xxxxxxxxxxxxxxxxxxx\"\"&gt;&lt;/div&gt;</pre>\n<h4>JavaScript</h4>\n<p>We can use Ajax to perform asynchronous HTTP (Ajax) requests. Enter the Ajax URL with the Invoke URL we got when building the API\u00a0gateway.</p>\n<h3>Host Static\u00a0Website</h3>\n<ol>\n<li>Back in the S3 Console, select the bucket that was created\u00a0earlier</li>\n<li>Upload your website files into a\u00a0bucket</li>\n<li>When finished, select the Properties tab</li>\n<li>Select Static website\u00a0hosting</li>\n<li>Fill in the index and document\u00a0error</li>\n<li>Make sure Block Public access is not\u00a0checked</li>\n<li>Still on the Permissions tab, select Bucket Policy. Enter the following policy document into the policy bucket editor, replacing [YOUR_BUCKET_NAME] with the bucket name that was\u00a0created.</li>\n</ol>\n<pre>{<br>   \"\"Version\"\":\"\"2012-10-17\"\",<br>   \"\"Statement\"\":[<br>      {<br>         \"\"Effect\"\":\"\"Allow\"\",<br>         \"\"Principal\"\":\"\"*\"\",<br>         \"\"Action\"\":\"\"s3:GetObject\"\",<br>         \"\"Resource\"\":\"\"arn:aws:s3:::[YOUR_BUCKET_NAME]/*\"\"<br>      }<br>   ]<br>}</pre>\n<h3>Configure the Domain on Route\u00a053</h3>\n<ol>\n<li>On Amazon Route 53 we can register a new domain or make Route 53 a DNS service for an existing\u00a0domain</li>\n<li>I already have my own domain, so I made Amazon Route 53 the DNS Service for my\u00a0domain</li>\n<li>On the <a href=\"https://console.aws.amazon.com/route53/home\">Route 53 Console</a>, select Create Hosted\u00a0Zone.</li>\n<li>On the Create Hosted Zone panel, enter the domain\u00a0name</li>\n<li>In the Type, leave the default on the Public Hosted\u00a0Zone</li>\n<li>Select Create.</li>\n</ol>\n<h3>Request SSL Certificate in AWS Certificate Manager</h3>\n<ol>\n<li>Open ACM Console or access\u00a0<a href=\"https://console.aws.amazon.com/apigateway/\">here</a>\n</li>\n<li>select Request a Certificate</li>\n<li>Select Request a public certificate</li>\n<li>Add a domain name with your own domain name, for example example.com or *.example.com</li>\n<li>We need to validate the certificate request, how to select DNS validation or email validation. Here I use DNS validation because it\u2019s faster and\u00a0easier.</li>\n<li>Add a CNAME on Amazon Route 53 or simply click the button below your domain to add it automatically.</li>\n</ol>\n<h3>Create a CloudFront Web Distribution</h3>\n<ol>\n<li>Open the CloudFront console or access\u00a0<a href=\"https://console.aws.amazon.com/cloudfront/home\">here</a>\n</li>\n<li>Create a distribution</li>\n<li>select Origin Domain Name with the bucket name created\u00a0earlier.</li>\n<li>Select Redirect HTTP to\u00a0HTTPS</li>\n<li>Select Yes in the Restrict Bucket Access\u00a0section</li>\n<li>In the Distribution Settings, use the Custom SSL Certificate and select the certificate that was created in\u00a0ACM</li>\n<li>Scroll and find Default Root Object, enter the default file Index.html</li>\n<li>Leave everything else default and create distribution.</li>\n<li>Wait until the status is Deployed, it usually takes a few\u00a0minutes.</li>\n<li>Write down the Domain name from cloudfront</li>\n</ol>\n<h3>Using Custom Domain on Route\u00a053</h3>\n<ol>\n<li>Return to the Route 53\u00a0Console</li>\n<li>Select a domain that has been registered</li>\n<li>Select Create Record\u00a0Set</li>\n<li>We will create 2 record\u00a0sets</li>\n<li>The first is example.com and the second is <a href=\"http://www.example.com/\">www.example.com</a>\n</li>\n<li>Use A record and select the created CloudFront.</li>\n</ol>\n<p>That\u2019s it, we\u2019ve built a serverless static website with reCaptcha protection and a notification for the owner or admin if someone sends a message on the\u00a0form.</p>\n<p>Reference:</p>\n<ol><li>AWS Documentations</li></ol>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=09d2081339dd\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":[]},{"title":"Easy Ways to Manage Access Control List (ACL) on Linux","pubDate":"2024-03-31 21:09:58","link":"https://medium.com/@kajolkabiraj6/easy-ways-to-manage-access-control-list-acl-on-linux-783f71561d92?source=rss-29ce35408d19------2","guid":"https://medium.com/p/783f71561d92","author":"kjo-codes","thumbnail":"","description":"\n<p>There are many challenges in managing Linux in a modern business environment, including that we must be able to manage who has access to information or what is commonly called the Access Control List. To do that, you can use basic linux filesystem permissions.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*uIymcJBViL9CLuIZP42yAg.jpeg\"></figure><p>There are many challenges in managing Linux in a modern business environment, including that we must be able to manage who has access to information or what is commonly called the Access Control List. To do that, you can use <em>basic linux filesystem permissions</em>.</p>\n<h3>Review Basic Linux Permissions</h3>\n<p>There are 3 types of permissions on Linux filesystems, here is a simple explanation:</p>\n<ul>\n<li>\n<strong>U</strong> ser or user\u00a0owner</li>\n<li>\n<strong>G</strong> roup or owner\u00a0group</li>\n<li>\n<strong>O</strong> ther or someone other than\u00a0above</li>\n</ul>\n<p>Of the three types of permissions above, each can be given 3 types of access,\u00a0namely:</p>\n<ul>\n<li>\n<strong>R</strong> ead</li>\n<li>\n<strong>W</strong> rite</li>\n<li>e <strong>X</strong>\u00a0ecute</li>\n</ul>\n<p>For example there is a directory containing files from the development department with the following permissions:</p>\n<pre>drwxrwxr-x  2 development development 6 Jan  8 15:13</pre>\n<p>From the above example, the development user (owner user) can read and write to the directory. Members of the development group (or owner group) can also read and write directories, while other people or others cannot write. For the record, the above example allows other to read or view the directory contents.</p>\n<h3>Linux Access Control List\u00a0(ACL)</h3>\n<p>In certain situations, basic permissions can be tricky because each file and directory can only have one user and one group owner at a time. This type of situation can be resolved by Linux Access Control Lists\u00a0(ACLs).</p>\n<p>ACLs make it possible to apply a more specific set of permissions to a file or directory without changing ownership and permissions.</p>\n<h3>Set ACLs</h3>\n<p>This section discusses using the Access Control List or ACL on Linux. This allows an easier time to set up permissions for automated tasks such as implementing web applications.</p>\n<p>Make sure the ACL is installed, if you haven\u2019t already run the command sudo apt install\u00a0acl.</p>\n<p>In this case it will show the ACL setting on the directory. These ACL permissions can be inherited by the parent directories. Setting the default ACL for a location is very effective, as it ignores the need to always reset user / group permissions after any file operation (eg creating a new\u00a0file).</p>\n<h4>Viewing ACLs</h4>\n<p>To be able to see the current ACL in a specific directory use the command\u00a0getfacl:</p>\n<pre># getfacl /var/www</pre>\n<h4>Installing ACLs</h4>\n<p>The syntax for setting an ACL looks like\u00a0this:</p>\n<pre>setfacl [option] [action/specification] file</pre>\n<p>Set ACLs for specific users and directories:</p>\n<pre># setfacl -R -m u:johndoe:rwx /var/www</pre>\n<p>Syntax description above:</p>\n<ul>\n<li>setfacl: Set\u00a0ACL</li>\n<li>-R: Recursive into files and directories</li>\n<li>-m: Modifying ACLs (-x for removing)</li>\n<li>u:johndoe:rwx: User johndoe will get rwx permissions</li>\n<li>/var/www: Gives permissions to directory /var/www</li>\n</ul>\n<p>Set ACLs for groups in a specific directory:</p>\n<pre># setfacl -R -m g:www-data:rwx /var/www</pre>\n<p>Syntax description above:</p>\n<ul><li>g:www-data:rwx: Members of the www-data group get rwx permissions</li></ul>\n<h4>Removes ACLs</h4>\n<pre># setfacl -x g:www-data /var/www</pre>\n<p>Syntax description above:</p>\n<ul><li>-x: Delete ACL's for g:www-data in\u00a0/var/www</li></ul>\n<h3>Sample case</h3>\n<p>To better understand, below is a case example in implementing a web application. There are 2 users with different permissions. Also read how to configure the initial server for deploying web applications <a href=\"https://adityacprtm.dev/blog/kentuk-awal-untuk-mengamanan-server-baru\">here</a>.</p>\n<h4>Create User</h4>\n<p>Create the first user named jane and add it to the sudo group to be able to perform the sudo\u00a0command.</p>\n<pre># adduser jane<br># usermod -a -G sudo jane</pre>\n<p>The second user is named bob, bob is the user who can deploy the website and is a member of the www-data\u00a0group.</p>\n<pre># adduser bob<br># usermod -a -G www-data bob</pre>\n<p>To make sure the files in the web root belong to the group of www-data, run the command below. This is not required for ACL permissions, but is done for consistency.</p>\n<pre># chown -R www-data:www-data /var/www</pre>\n<h4>Use of\u00a0ACLs</h4>\n<p>Users will be granted permission to read/write/execute files and directories using ACLs instead of basic Linux permissions.</p>\n<p>See set ACL by default, this is separate from basic user/group permissions.</p>\n<pre># getfacl /var/www</pre>\n<p>Next, give jane user permission to change the web files in the /var/www directory. Jane doesn't technically need this, as she can use the sudo\u00a0command.</p>\n<pre># setfacl -R -m u:jane:rwx /var/www</pre>\n<p>Above specifies the ACL for an existing file or directory, here it will recursively (-R) set the default (-d flag) for future files or directories.</p>\n<pre># setfacl -Rd -m u:jane:rwx /var/www</pre>\n<p>Check the command above has been added successfully</p>\n<pre># getfacl /var/www</pre>\n<blockquote>\n<em>The previous two commands can be combined to set defaults and permissions: </em><em>setfacl -R -m u:jane:rwx,d:u:jane:rwx /var/www</em>\n</blockquote>\n<p>Next, grant group-based permissions via ACLs to web files. This more efficient way for the user allows editing of web files, regardless of who owns the files as long as they are members of the\u00a0group.</p>\n<pre># setfacl -R -m g:www-data:rwx /var/www</pre>\n<p>Or use default (-d) for the\u00a0future</p>\n<pre># setfacl -Rd -m g:www-data:rwx /var/www</pre>\n<p>If so, now TIAP USER who is a member of the www-data group can edit files in the /var/www directory. To make sure the ACL is checked by running the following command:</p>\n<pre># getfacl /var/www</pre>\n<p>That\u2019s it! We can also read articles from the Redhat website about ACL\u00a0<a href=\"https://www.redhat.com/sysadmin/linux-access-control-lists\">here</a>.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=783f71561d92\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>There are many challenges in managing Linux in a modern business environment, including that we must be able to manage who has access to information or what is commonly called the Access Control List. To do that, you can use basic linux filesystem permissions.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*uIymcJBViL9CLuIZP42yAg.jpeg\"></figure><p>There are many challenges in managing Linux in a modern business environment, including that we must be able to manage who has access to information or what is commonly called the Access Control List. To do that, you can use <em>basic linux filesystem permissions</em>.</p>\n<h3>Review Basic Linux Permissions</h3>\n<p>There are 3 types of permissions on Linux filesystems, here is a simple explanation:</p>\n<ul>\n<li>\n<strong>U</strong> ser or user\u00a0owner</li>\n<li>\n<strong>G</strong> roup or owner\u00a0group</li>\n<li>\n<strong>O</strong> ther or someone other than\u00a0above</li>\n</ul>\n<p>Of the three types of permissions above, each can be given 3 types of access,\u00a0namely:</p>\n<ul>\n<li>\n<strong>R</strong> ead</li>\n<li>\n<strong>W</strong> rite</li>\n<li>e <strong>X</strong>\u00a0ecute</li>\n</ul>\n<p>For example there is a directory containing files from the development department with the following permissions:</p>\n<pre>drwxrwxr-x  2 development development 6 Jan  8 15:13</pre>\n<p>From the above example, the development user (owner user) can read and write to the directory. Members of the development group (or owner group) can also read and write directories, while other people or others cannot write. For the record, the above example allows other to read or view the directory contents.</p>\n<h3>Linux Access Control List\u00a0(ACL)</h3>\n<p>In certain situations, basic permissions can be tricky because each file and directory can only have one user and one group owner at a time. This type of situation can be resolved by Linux Access Control Lists\u00a0(ACLs).</p>\n<p>ACLs make it possible to apply a more specific set of permissions to a file or directory without changing ownership and permissions.</p>\n<h3>Set ACLs</h3>\n<p>This section discusses using the Access Control List or ACL on Linux. This allows an easier time to set up permissions for automated tasks such as implementing web applications.</p>\n<p>Make sure the ACL is installed, if you haven\u2019t already run the command sudo apt install\u00a0acl.</p>\n<p>In this case it will show the ACL setting on the directory. These ACL permissions can be inherited by the parent directories. Setting the default ACL for a location is very effective, as it ignores the need to always reset user / group permissions after any file operation (eg creating a new\u00a0file).</p>\n<h4>Viewing ACLs</h4>\n<p>To be able to see the current ACL in a specific directory use the command\u00a0getfacl:</p>\n<pre># getfacl /var/www</pre>\n<h4>Installing ACLs</h4>\n<p>The syntax for setting an ACL looks like\u00a0this:</p>\n<pre>setfacl [option] [action/specification] file</pre>\n<p>Set ACLs for specific users and directories:</p>\n<pre># setfacl -R -m u:johndoe:rwx /var/www</pre>\n<p>Syntax description above:</p>\n<ul>\n<li>setfacl: Set\u00a0ACL</li>\n<li>-R: Recursive into files and directories</li>\n<li>-m: Modifying ACLs (-x for removing)</li>\n<li>u:johndoe:rwx: User johndoe will get rwx permissions</li>\n<li>/var/www: Gives permissions to directory /var/www</li>\n</ul>\n<p>Set ACLs for groups in a specific directory:</p>\n<pre># setfacl -R -m g:www-data:rwx /var/www</pre>\n<p>Syntax description above:</p>\n<ul><li>g:www-data:rwx: Members of the www-data group get rwx permissions</li></ul>\n<h4>Removes ACLs</h4>\n<pre># setfacl -x g:www-data /var/www</pre>\n<p>Syntax description above:</p>\n<ul><li>-x: Delete ACL's for g:www-data in\u00a0/var/www</li></ul>\n<h3>Sample case</h3>\n<p>To better understand, below is a case example in implementing a web application. There are 2 users with different permissions. Also read how to configure the initial server for deploying web applications <a href=\"https://adityacprtm.dev/blog/kentuk-awal-untuk-mengamanan-server-baru\">here</a>.</p>\n<h4>Create User</h4>\n<p>Create the first user named jane and add it to the sudo group to be able to perform the sudo\u00a0command.</p>\n<pre># adduser jane<br># usermod -a -G sudo jane</pre>\n<p>The second user is named bob, bob is the user who can deploy the website and is a member of the www-data\u00a0group.</p>\n<pre># adduser bob<br># usermod -a -G www-data bob</pre>\n<p>To make sure the files in the web root belong to the group of www-data, run the command below. This is not required for ACL permissions, but is done for consistency.</p>\n<pre># chown -R www-data:www-data /var/www</pre>\n<h4>Use of\u00a0ACLs</h4>\n<p>Users will be granted permission to read/write/execute files and directories using ACLs instead of basic Linux permissions.</p>\n<p>See set ACL by default, this is separate from basic user/group permissions.</p>\n<pre># getfacl /var/www</pre>\n<p>Next, give jane user permission to change the web files in the /var/www directory. Jane doesn't technically need this, as she can use the sudo\u00a0command.</p>\n<pre># setfacl -R -m u:jane:rwx /var/www</pre>\n<p>Above specifies the ACL for an existing file or directory, here it will recursively (-R) set the default (-d flag) for future files or directories.</p>\n<pre># setfacl -Rd -m u:jane:rwx /var/www</pre>\n<p>Check the command above has been added successfully</p>\n<pre># getfacl /var/www</pre>\n<blockquote>\n<em>The previous two commands can be combined to set defaults and permissions: </em><em>setfacl -R -m u:jane:rwx,d:u:jane:rwx /var/www</em>\n</blockquote>\n<p>Next, grant group-based permissions via ACLs to web files. This more efficient way for the user allows editing of web files, regardless of who owns the files as long as they are members of the\u00a0group.</p>\n<pre># setfacl -R -m g:www-data:rwx /var/www</pre>\n<p>Or use default (-d) for the\u00a0future</p>\n<pre># setfacl -Rd -m g:www-data:rwx /var/www</pre>\n<p>If so, now TIAP USER who is a member of the www-data group can edit files in the /var/www directory. To make sure the ACL is checked by running the following command:</p>\n<pre># getfacl /var/www</pre>\n<p>That\u2019s it! We can also read articles from the Redhat website about ACL\u00a0<a href=\"https://www.redhat.com/sysadmin/linux-access-control-lists\">here</a>.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=783f71561d92\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":[]}]}